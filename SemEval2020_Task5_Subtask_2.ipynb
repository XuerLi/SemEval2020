{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Subtask_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlTujgsUAGFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/train.csv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4EnsYmpn5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1]\n",
        "})\n",
        "\n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4DctzKMLVOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install allennlp\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIJgOTAePV-e",
        "colab_type": "text"
      },
      "source": [
        "START AGAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7r33OAFtOM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_modal(obj):\n",
        "    arr = list() # full set of constituents\n",
        "    modal= list() # only the modal phrases\n",
        "    past = list() # only the past phrases\n",
        "    noun = list()\n",
        "    verb = list()\n",
        "\n",
        "    def extract(obj, arr):\n",
        "        \n",
        "        if isinstance(obj, dict):\n",
        "            for k, v in obj.items():\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    extract(v, arr)\n",
        "                  \n",
        "                if k=='nodeType' and v=='NP':\n",
        "                    arr.append(v)\n",
        "                if k=='nodeType' and v=='MD':\n",
        "                    arr.append(v)\n",
        "                if k=='nodeType' and v=='VP':    \n",
        "                    arr.append(v)\n",
        "                if k=='nodeType' and v=='VBD': # Verb, past tense\n",
        "                    arr.append(v) \n",
        "                if k=='nodeType' and v=='ADVP': # Adverb Phrase\n",
        "                    arr.append(v)           \n",
        "                if k=='nodeType' and v=='RB':   # Adverb \n",
        "                    arr.append(v)\n",
        "                if k=='nodeType' and v=='IN':    \n",
        "                    arr.append(v)        \n",
        "\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "\n",
        "              if isinstance(item, dict):\n",
        "                  if 'MD' in arr: \n",
        "                    arr.remove('MD')\n",
        "                    modal.append(obj)\n",
        "                  if 'NP' in arr: \n",
        "                    arr.remove('NP')\n",
        "                    noun.append(obj)  \n",
        "                  if 'VP' in arr:\n",
        "                    arr.remove('VP')\n",
        "                    verb.append(obj)\n",
        "                    if 'wish' in obj[0]['word'].lower():\n",
        "                      past.append(obj)  \n",
        "                  if 'VBD' in arr:\n",
        "                    arr.remove('VBD')\n",
        "                    if 'were' in obj[0]['word'].lower():\n",
        "                      past.append(obj)\n",
        "                    if 'was' in obj[0]['word'].lower():\n",
        "                      past.append(obj)  \n",
        "                    if 'had' in obj[0]['word'].lower():\n",
        "                      past.append(obj)\n",
        "                  if 'ADVP' in arr:\n",
        "                    arr.remove('ADVP')  \n",
        "                    modal.append(obj)  \n",
        "                  if 'RB' in arr: \n",
        "                    arr.remove('RB')\n",
        "                    if 'even' in obj[0]['word'].lower():\n",
        "                      past.append(obj)\n",
        "                    if 'whichever' in obj[0]['word'].lower():\n",
        "                      past.append(obj)  \n",
        "                    if 'whatever' in obj[0]['word'].lower(): \n",
        "                      past.append(obj)\n",
        "                    if 'however' in obj[0]['word'].lower(): \n",
        "                      past.append(obj)\n",
        "                    if 'regardless' in obj[0]['word'].lower(): \n",
        "                      past.append(obj)\n",
        "                    if 'notwithstanding' in obj[0]['word'].lower(): \n",
        "                      past.append(obj)  \n",
        "                  if 'IN' in arr: \n",
        "                     arr.remove('IN')   \n",
        "                     if 'in' in obj[0]['word'].lower(): \n",
        "                       past.append(obj) \n",
        "                     if 'if' in obj[0]['word'].lower():\n",
        "                       past.append(obj)\n",
        "                     if 'for' in obj[0]['word'].lower():\n",
        "                       past.append(obj) \n",
        "                     if 'but' in obj[0]['word'].lower():\n",
        "                       past.append(obj)\n",
        "                     if 'because' in obj[0]['word'].lower():\n",
        "                       past.append(obj)  \n",
        "                     if 'although' in obj[0]['word'].lower():\n",
        "                       past.append(obj)\n",
        "               \n",
        "              #arr.append(item) # uncomment for the full set\n",
        "              #print(item)\n",
        "\n",
        "              extract(item, arr)\n",
        "  \n",
        "        return arr\n",
        "\n",
        "    results = extract(obj, arr)\n",
        "\n",
        "    return modal, past, noun, verb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm_UQ7ejvUsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_children(obj):\n",
        "    arr = list()\n",
        "\n",
        "    def separate(obj, arr):\n",
        "        \n",
        "        if isinstance(obj, dict):\n",
        "\n",
        "            for k, v in obj.items():\n",
        "              if k != 'children':\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    separate(v, arr)\n",
        "                elif k == 'word':      \n",
        "                    arr.append(v)\n",
        "\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "                separate(item, arr)\n",
        "         \n",
        "        return arr\n",
        "\n",
        "    results = separate(obj, arr)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XYFHp-5KyQ7",
        "colab": {}
      },
      "source": [
        "def extract_constituents():\n",
        " for key, value in prediction.items():\n",
        "  if (key=='hierplane_tree'):\n",
        "    for key, value in value.items():\n",
        "      if (key=='root'):\n",
        "        for key, value in value.items():\n",
        "          if (key == 'children'):\n",
        "            return extract_modal(value)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6BHdEZXkTu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def simplify(constit):\n",
        "  gist = list();\n",
        "  sentence = set()  # rebuild with checking for overlap\n",
        "  for c in constit:\n",
        "      #print(c)\n",
        "      p = separate_children(c) # candidate phrases\n",
        "      #print(p)\n",
        "      for head in list(p):\n",
        "        #print(head)\n",
        "        phrase = word_tokenize(head)\n",
        "        #print(phrase)\n",
        "        words = set(phrase)\n",
        "        if len(sentence.intersection(words)) < len(words):\n",
        "          sentence.update(words)\n",
        "          gist.extend(phrase)\n",
        "  result = str()\n",
        "  for word in gist:\n",
        "    if word != '\\'ve' and word != 'n\\'t': # all exceptions\n",
        "      result = result + ' '\n",
        "    result = result + word  \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1os8EQvxh7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "original = \"I don't think any of us---even economic gurus like Paul Krugman---really, truly understand just how bad it could've gotten 'on Main Street' if the stimulus bill had become hamstrung by a filibuster threat or recalcitrant conservadems, the way so much of our legislation has since.\"\n",
        "\n",
        "modal = list()\n",
        "nounm = list()\n",
        "past = list() \n",
        "nounp = list()\n",
        "nouns = list()\n",
        "\n",
        "texts = original.rsplit(',')\n",
        "for text in texts:\n",
        "  text.replace('\\\"','\\'')\n",
        "  #print(text)\n",
        "\n",
        "  prediction = predictor.predict(sentence=text)\n",
        "  mod, pas, nou, ver = extract_constituents()\n",
        "\n",
        "  for u in nou:\n",
        "    nu = simplify(u) \n",
        "    if nu not in nouns:\n",
        "      nouns.append(nu) \n",
        "\n",
        "  if len(mod)==0:\n",
        "    for p in pas:\n",
        "      pa = simplify(p)\n",
        "      if pa not in past:\n",
        "          past.append(pa) \n",
        "\n",
        "  for m in mod:\n",
        "    md = simplify(m) # string gist\n",
        "\n",
        "    for nm in reversed(sorted(nouns,key=len)):  \n",
        "      if nm in md:   \n",
        "        nounm.append(nm)\n",
        "        nouns.remove(nm)\n",
        "    \n",
        "    for p in pas:\n",
        "      pa = simplify(p)\n",
        "     \n",
        "      if pa in md and len(md) > len(pa):\n",
        "        if md.index(pa) > 0 :\n",
        "          md = md[0:md.index(pa)]\n",
        "        else:\n",
        "          md = md.replace(pa,'')    \n",
        "\n",
        "      if md in pa and len(pa) > len(md):\n",
        "        if pa.index(md) > 0 :\n",
        "          pa = pa[0:pa.index(md)] \n",
        "        else:\n",
        "          pa = pa.replace(md,'')  \n",
        "            \n",
        "      for np in reversed(sorted(nounp,key=len)):\n",
        "        if np in pa and len(pa) > len(np): \n",
        "          if pa.index(np) > 0 :\n",
        "            pa = pa[0:pa.index(np)]\n",
        "          else:\n",
        "            pa = pa.replace(np,'')  \n",
        "          nounp.append(np)\n",
        "          nouns.remove(np)    \n",
        "      \n",
        "      if pa not in past:\n",
        "        past.append(pa) \n",
        "\n",
        "    if md not in modal:        \n",
        "      modal.append(md) \n",
        "\n",
        "print(nounm)\n",
        "print(nounp)\n",
        "\n",
        "antecedents = past.copy()\n",
        "consequents = modal.copy()\n",
        "\n",
        "count=0 # max 10 times\n",
        "while count < 10 and len(past) > 0 and len(modal) > 1: # consequent can't be empty!\n",
        "  count += 1\n",
        "  for m in sorted(modal,key=len):\n",
        "    for p in reversed(sorted(past,key=len)): # start matching from smaller fragments\n",
        "        if p in m and len(m) > len(p): \n",
        "          #print(m,p)\n",
        "          if p in past and len(past) > 1:\n",
        "            past.remove(p)  \n",
        "          if m in modal and len(modal) > 1: \n",
        "            modal.remove(m)  \n",
        "\n",
        "print(modal)\n",
        "print(consequents)\n",
        "print(antecedents)\n",
        "\n",
        "for a in antecedents:\n",
        "  for c in consequents:\n",
        "    if c in a: \n",
        "      if a in past and len(past) > 1:\n",
        "          past.remove(a)\n",
        "\n",
        "for p1 in past:\n",
        "  for p2 in past:\n",
        "    if p2 in p1 and len(p1) > len(p2):\n",
        "      past.remove(p2)   \n",
        "\n",
        "for p2 in past:\n",
        "  for p1 in past:\n",
        "    if p1 in p2 and len(p2) > len(p1):\n",
        "      past.remove(p1)                \n",
        "\n",
        "print(past)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIQLmP3AnyF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "c572c634-879f-4d25-e3a5-e62c1b4649ee"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "prefix = '/content/'\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df = test_df.drop(index=0)\n",
        "  \n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1], \n",
        "    'labels': ''\n",
        "})\n",
        "\n",
        "count = test_df['id'].count()\n",
        "print(count)\n",
        "\n",
        "\n",
        "i = 0\n",
        "j = 0\n",
        "modal_df= pd.DataFrame(columns=['id','labels','text'])\n",
        "past_df = pd.DataFrame(columns=['id','labels','text'])\n",
        "\n",
        "for ind in tqdm(test_df.index): \n",
        "  original = test_df['text'][ind]\n",
        "\n",
        "  modal = list()\n",
        "  nounm = list()\n",
        "  past = list() \n",
        "  nounp = list()\n",
        "  nouns = list()\n",
        "\n",
        "  texts = original.rsplit(',')\n",
        "  for text in texts:\n",
        "    text.replace('\\\"','\\'')\n",
        "    #print(text)\n",
        "\n",
        "    prediction = predictor.predict(sentence=text)\n",
        "    mod, pas, nou, ver = extract_constituents()\n",
        "\n",
        "    for u in nou:\n",
        "      nu = simplify(u) \n",
        "      if nu not in nouns:\n",
        "        nouns.append(nu) \n",
        "\n",
        "    if len(mod)==0:\n",
        "      for p in pas:\n",
        "        pa = simplify(p)\n",
        "        if pa not in past:\n",
        "            past.append(pa) \n",
        "\n",
        "    for m in mod:\n",
        "      md = simplify(m) # string gist\n",
        "\n",
        "      for nm in reversed(sorted(nouns,key=len)):  \n",
        "        if nm in md:   \n",
        "          nounm.append(nm)\n",
        "          nouns.remove(nm)\n",
        "      \n",
        "      for p in pas:\n",
        "        pa = simplify(p)\n",
        "      \n",
        "        if pa in md and len(md) > len(pa):\n",
        "          if md.index(pa) > 0 :\n",
        "            md = md[0:md.index(pa)]\n",
        "          else:\n",
        "            md = md.replace(pa,'')    \n",
        "\n",
        "        if md in pa and len(pa) > len(md):\n",
        "          if pa.index(md) > 0 :\n",
        "            pa = pa[0:pa.index(md)] \n",
        "          else:\n",
        "            pa = pa.replace(md,'')  \n",
        "              \n",
        "        for np in reversed(sorted(nounp,key=len)):\n",
        "          if np in pa and len(pa) > len(np): \n",
        "            if pa.index(np) > 0 :\n",
        "              pa = pa[0:pa.index(np)]\n",
        "            else:\n",
        "              pa = pa.replace(np,'')  \n",
        "            nounp.append(np)\n",
        "            nouns.remove(np)    \n",
        "        \n",
        "        if pa not in past:\n",
        "          past.append(pa) \n",
        "\n",
        "      if md not in modal:        \n",
        "        modal.append(md) \n",
        "\n",
        "  antecedents = past.copy()\n",
        "  consequents = modal.copy()\n",
        "\n",
        "  count=0 # max 10 times\n",
        "  while count < 10 and len(past) > 0 and len(modal) > 1: # consequent can't be empty!\n",
        "    count += 1\n",
        "    for m in sorted(modal,key=len):\n",
        "      for p in reversed(sorted(past,key=len)): # start matching from smaller fragments\n",
        "          if p in m and len(m) > len(p): \n",
        "            #print(m,p)\n",
        "            if p in past and len(past) > 1:\n",
        "              past.remove(p)  \n",
        "            if m in modal and len(modal) > 1: \n",
        "              modal.remove(m)  \n",
        "\n",
        "  for a in antecedents:\n",
        "    for c in consequents:\n",
        "      if c in a: \n",
        "        if a in past and len(past) > 1:\n",
        "            past.remove(a)\n",
        "\n",
        "  for p1 in past:\n",
        "    for p2 in past:\n",
        "      if p2 in p1 and len(p1) > len(p2):\n",
        "        past.remove(p2)   \n",
        "\n",
        "  for p2 in past:\n",
        "    for p1 in past:\n",
        "      if p1 in p2 and len(p2) > len(p1):\n",
        "        past.remove(p1)  \n",
        "\n",
        "\n",
        "\n",
        "  m_row = pd.Series(data={\n",
        "    'id': test_df['id'][ind],\n",
        "    'labels':'1', # gold label\n",
        "    'text': test_df['text'][ind]\n",
        "  }, name = str(i) )\n",
        "  modal_df = modal_df.append(m_row)  \n",
        "  i = i+1\n",
        "\n",
        "  p_row = pd.Series(data={\n",
        "    'id': test_df['id'][ind],\n",
        "    'labels':'1', # gold label\n",
        "    'text': test_df['text'][ind]\n",
        "  }, name = str(j) )\n",
        "  past_df = past_df.append(p_row)  \n",
        "  j = j+1\n",
        "\n",
        "\n",
        "  for m in modal:\n",
        "    m_row = pd.Series(data={\n",
        "      'id': test_df['id'][ind]+'A'+ str(i),\n",
        "      'labels':'0',\n",
        "      'text': m\n",
        "    }, name = str(i) )\n",
        "    modal_df = modal_df.append(m_row)  \n",
        "    i = i+1\n",
        "    \n",
        "  for p in past:\n",
        "    p_row = pd.Series(data={\n",
        "      'id': test_df['id'][ind]+'C'+ str(j),\n",
        "      'labels':'0',\n",
        "      'text': p\n",
        "    }, name = str(j) )\n",
        "    past_df = past_df.append(p_row)  \n",
        "    j = j+1\n",
        "\n",
        "  sleep(1)  \n",
        "\n",
        "past_df.to_csv(prefix+'antecedents.tsv', sep='\\t', index=False, header=False)\n",
        "modal_df.to_csv(prefix+'consequents.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1950 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "1950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 1/1950 [00:01<1:00:43,  1.87s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3w26wdnuriO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/antecedents.tsv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/\n",
        "!mv /content/consequents.tsv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}