{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Subtask_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlTujgsUAGFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/train.csv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4EnsYmpn5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1].replace(r'\\n', ' ', regex=True),\n",
        "    'past':''*test_df.shape[1],\n",
        "    'modal':''*test_df.shape[1],\n",
        "    'antecedent':''*test_df.shape[1],\n",
        "    'consequent':''*test_df.shape[1]\n",
        "})\n",
        "\n",
        "  \n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4DctzKMLVOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install allennlp\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIJgOTAePV-e",
        "colab_type": "text"
      },
      "source": [
        "START AGAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7r33OAFtOM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_modal(obj):\n",
        "    arr = list() # full set of constituents\n",
        "    modal= list() # only the modal phrases\n",
        "    past = list() # only the past phrases\n",
        "    noun = list()\n",
        "\n",
        "    def extract(obj, arr):\n",
        "        \n",
        "        if isinstance(obj, dict):\n",
        "            for k, v in obj.items():\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    extract(v, arr)\n",
        "                  \n",
        "                elif k=='nodeType' and v=='NP':\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='MD':\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='VBD': # Verb, past tense\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='VBN': # Verb, past participle\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='RB': # Adverb (eg \"Even\" if past...)  \n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='IN':  # Preposition or conjunction (eg \"if\")\n",
        "                    arr.append(v)\n",
        "\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "\n",
        "              if isinstance(item, dict):\n",
        "                  if 'MD' in arr: \n",
        "                    arr.remove('MD')\n",
        "                    modal.append(obj)\n",
        "                    past.append(obj)\n",
        "                  elif 'NP' in arr: \n",
        "                    arr.remove('NP')\n",
        "                    noun.append(obj)  \n",
        "                  elif 'VBD' in arr: \n",
        "                    arr.remove('VBD')\n",
        "                    past.append(obj) \n",
        "                  elif 'VBD' in arr: \n",
        "                    arr.remove('VBN')\n",
        "                    past.append(obj)\n",
        "                  elif 'RB' in arr: \n",
        "                    arr.remove('RB')\n",
        "                    if 'even' in obj[0]['word'].lower():\n",
        "                      past.append(obj)\n",
        "                  elif 'IN' in arr: \n",
        "                     arr.remove('IN')   \n",
        "                     if 'if' in obj[0]['word'].lower():  \n",
        "                       past.append(obj)\n",
        "                      #print(obj)\n",
        "     \n",
        "              #arr.append(item) # uncomment for the full set\n",
        "              #print(item)\n",
        "\n",
        "              extract(item, arr)\n",
        "  \n",
        "        return arr\n",
        "\n",
        "    results = extract(obj, arr)\n",
        "    return modal, past, noun # result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm_UQ7ejvUsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_children(obj):\n",
        "    arr = list()\n",
        "\n",
        "    def separate(obj, arr):\n",
        "        \n",
        "        if isinstance(obj, dict):\n",
        "\n",
        "            for k, v in obj.items():\n",
        "              if k != 'children':\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    separate(v, arr)\n",
        "                elif k == 'word':      \n",
        "                    arr.append(v)\n",
        "\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "                separate(item, arr)\n",
        "         \n",
        "        return arr\n",
        "\n",
        "    results = separate(obj, arr)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XYFHp-5KyQ7",
        "colab": {}
      },
      "source": [
        "def extract_constituents():\n",
        " modal = list()\n",
        " nounm = list()\n",
        " past = list() \n",
        " nounp = list()\n",
        " nouns = list()\n",
        "\n",
        " for key, value in prediction.items():\n",
        "  if (key=='hierplane_tree'):\n",
        "    for key, value in value.items():\n",
        "      if (key=='root'):\n",
        "        for key, value in value.items():\n",
        "          if (key == 'children'):\n",
        "\n",
        "            mod, pas, nou = extract_modal(value)\n",
        "            \n",
        "            for u in nou:\n",
        "              nu = simplify(u) \n",
        "              if nu not in nouns:\n",
        "                nouns.append(nu) \n",
        "\n",
        "            for m in mod:\n",
        "              md = simplify(m) # string gist\n",
        "              for nm in reversed(sorted(nouns,key=len)):  \n",
        "                if nm in md:   \n",
        "                  nounm.append(nm)\n",
        "                  nouns.remove(nm)\n",
        "\n",
        "              for p in pas:\n",
        "                pa = simplify(p)\n",
        "\n",
        "                if pa in md and len(md) > len(pa):\n",
        "                   if md.index(pa) > 0 :\n",
        "                     md = md[0:md.index(pa)]\n",
        "                   else:\n",
        "                     md = str(md).replace(str(pa),'')   \n",
        "                if md in pa and len(pa) > len(md):\n",
        "                   if pa.index(md) > 0 :\n",
        "                     pa = pa[0:pa.index(md)]  \n",
        "                   else:\n",
        "                     pa = str(pa).replace(str(md),'')  \n",
        "                for np in reversed(sorted(nouns,key=len)):  \n",
        "                  if np in pa and len(pa) > len(np): \n",
        "                    if pa.index(np) > 0 :\n",
        "                      pa = pa[0:pa.index(np)]\n",
        "                    else:\n",
        "                      pa = str(pa).replace(str(np),'')  \n",
        "                    nounp.append(np)\n",
        "                    nouns.remove(np)\n",
        "                if md in pa:\n",
        "                   if pa.index(md) > 0 :\n",
        "                     pa = pa[0:pa.index(md)]  \n",
        "                   else:\n",
        "                     pa = str(pa).replace(str(md),'')      \n",
        "\n",
        "                if pa not in past:\n",
        "                  past.append(pa) \n",
        "              if md not in modal:        \n",
        "                modal.append(md) \n",
        "                \n",
        "              for p1 in past:\n",
        "                for p2 in past:\n",
        "                  if p2 in p1:\n",
        "                    past.remove(p2) \n",
        "              \n",
        "            return modal, past, nouns, nounm, nounp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6BHdEZXkTu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def simplify(constit):\n",
        "  gist = list();\n",
        "  sentence = set()  # rebuild with checking for overlap\n",
        "  for c in constit:\n",
        "      #print(c)\n",
        "      p = separate_children(c) # candidate phrases\n",
        "      #print(p)\n",
        "      for head in list(p):\n",
        "        #print(head)\n",
        "        phrase = word_tokenize(head)\n",
        "        #print(phrase)\n",
        "        words = set(phrase)\n",
        "        if len(sentence.intersection(words)) < len(words):\n",
        "          sentence.update(words)\n",
        "          gist.extend(phrase)\n",
        "  #print(gist)\n",
        "  return ' '.join(map(str, gist))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "72f60299-bad4-47a8-aebd-c0d6d44eadd3",
        "id": "mU94XoTgLOhu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"67% of the embryos exposed to CRISPR-cas9 had only the correct version of the gene - higher than the 50% that would have been expected had the technique not been used.\"\n",
        "text.replace('\\\"','\\'')\n",
        "#print(text)\n",
        "\n",
        "prediction = predictor.predict(sentence=text)\n",
        "modal, past, nouns, nounm, nounp = extract_constituents()\n",
        "print(nounm)\n",
        "print(modal)\n",
        "print(past)\n",
        "print(nounp)\n",
        "\n",
        "mindex = int(0)\n",
        "pindex = int(0)\n",
        "length = int(0)\n",
        "\n",
        "try : \n",
        "  for m in modal:\n",
        "    if len(m) > mindex and m in text :\n",
        "      pindex = text.index(m)\n",
        "      length = len(m)\n",
        "\n",
        "    for n in nounp:\n",
        "      if mindex > text.index(n):\n",
        "        mindex = text.index(n)  \n",
        "\n",
        "  print(text[mindex:pindex+length])\n",
        "\n",
        "  mindex = int(0)\n",
        "  pindex = int(0)\n",
        "  length = int(0)\n",
        "\n",
        "  for p in past:\n",
        "    if len(p) > pindex and p in text:\n",
        "      pindex = text.index(p)\n",
        "      mindex = text.index(p)\n",
        "      length = len(p) \n",
        "\n",
        "    for n in nounm:\n",
        "      if mindex > text.index(n):\n",
        "        mindex = text.index(n)\n",
        "      \n",
        "  print(text[mindex:pindex+length])    \n",
        "except ValueError:\n",
        "  print(mindex,pindex,length)\n",
        "\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['the technique']\n",
            "['would have been expected ']\n",
            "['had the technique not been used']\n",
            "['only the correct version of the gene']\n",
            "67% of the embryos exposed to CRISPR-cas9 had only the correct version of the gene - higher than the 50% that would have been expected \n",
            "had the technique not been used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIQLmP3AnyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "prefix = '/content/'\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df = test_df.drop(index=0)\n",
        "  \n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1].replace(r'\\n', ' ', regex=True),\n",
        "    'past':''*test_df.shape[1],\n",
        "    'modal':''*test_df.shape[1],\n",
        "    'antecedent':''*test_df.shape[1],\n",
        "    'consequent':''*test_df.shape[1]\n",
        "})\n",
        "\n",
        "count = test_df['id'].count()\n",
        "print(count)\n",
        "\n",
        "for ind in tqdm(test_df.index): \n",
        "  prediction = predictor.predict(sentence=test_df['text'][ind])\n",
        "  modal, past, nouns, nounm, nounp = extract_constituents()\n",
        "  test_df['modal'][ind] = modal\n",
        "  test_df['past'][ind] = past\n",
        "\n",
        "  text = test_df['text'][ind]\n",
        "  mindex = int(0)\n",
        "  pindex = int(0)\n",
        "  length = int(0)\n",
        "\n",
        "  try : \n",
        "    for m in modal:\n",
        "      if len(m) > mindex and m in text :\n",
        "        mindex = text.index(m)\n",
        "        length = len(m)\n",
        "\n",
        "    test_df['consequent'][ind]=text[mindex:mindex+length]\n",
        "\n",
        "    mindex = int(0)\n",
        "    pindex = int(0)\n",
        "    length = int(0)\n",
        "\n",
        "    for p in past:\n",
        "      if len(p) > pindex and p in text:\n",
        "        pindex = text.index(p)\n",
        "        mindex = text.index(p)\n",
        "        length = len(p) \n",
        "\n",
        "      for n in nounp:\n",
        "        if mindex > text.index(n):\n",
        "          mindex = text.index(n)\n",
        "        \n",
        "    test_df['antecedent'][ind] = text[mindex:pindex+length]    \n",
        "  except ValueError:\n",
        "    print(mindex,pindex,length)\n",
        "\n",
        "  sleep(1)\n",
        "\n",
        "test_df.to_csv(prefix+'test.tsv', sep='\\t', index=False, header=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3w26wdnuriO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/test.tsv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}