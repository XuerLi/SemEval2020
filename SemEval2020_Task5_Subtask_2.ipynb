{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Subtask_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlTujgsUAGFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/train.csv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB4EnsYmpn5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1].replace(r'\\n', ' ', regex=True),\n",
        "    'past':''*test_df.shape[1],\n",
        "    'modal':''*test_df.shape[1],\n",
        "    'antecedent':''*test_df.shape[1],\n",
        "    'consequent':''*test_df.shape[1]\n",
        "})\n",
        "\n",
        "  \n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4DctzKMLVOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install allennlp\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo-constituency-parser-2018.03.14.tar.gz\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIJgOTAePV-e",
        "colab_type": "text"
      },
      "source": [
        "START AGAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7r33OAFtOM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_modal(obj):\n",
        "    arr = list() # full set of constituents\n",
        "    modal= list() # only the modal phrases\n",
        "    past = list() # only the past phrases\n",
        "    noun = list()\n",
        "\n",
        "    def extract(obj, arr):\n",
        "        \n",
        "        if isinstance(obj, dict):\n",
        "            for k, v in obj.items():\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    extract(v, arr)\n",
        "                  \n",
        "                elif k=='nodeType' and v=='NP':\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='MD':\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='VBD': # Verb, past tense\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='VBN': # Verb, past participle\n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='RB': # Adverb (eg \"Even\" if past...)  \n",
        "                    arr.append(v)\n",
        "                elif k=='nodeType' and v=='IN':  # Preposition or conjunction (eg \"if\")\n",
        "                    arr.append(v)\n",
        "\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "\n",
        "              if isinstance(item, dict):\n",
        "                  if 'MD' in arr: \n",
        "                    arr.remove('MD')\n",
        "                    modal.append(obj)\n",
        "                    past.append(obj)\n",
        "                  elif 'NP' in arr: \n",
        "                    arr.remove('NP')\n",
        "                    noun.append(obj)  \n",
        "                  elif 'VBD' in arr: \n",
        "                    arr.remove('VBD')\n",
        "                    past.append(obj) \n",
        "                  elif 'VBD' in arr: \n",
        "                    arr.remove('VBN')\n",
        "                    past.append(obj)\n",
        "                  elif 'RB' in arr: \n",
        "                    arr.remove('RB')\n",
        "                    if 'even' in obj[0]['word'].lower():\n",
        "                      past.append(obj)\n",
        "                  elif 'IN' in arr: \n",
        "                     arr.remove('IN')   \n",
        "                     if 'if' in obj[0]['word'].lower():  \n",
        "                       past.append(obj)\n",
        "                      #print(obj)\n",
        "     \n",
        "              #arr.append(item) # uncomment for the full set\n",
        "              #print(item)\n",
        "\n",
        "              extract(item, arr)\n",
        "  \n",
        "        return arr\n",
        "\n",
        "    results = extract(obj, arr)\n",
        "\n",
        "    return modal, past, noun # result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm_UQ7ejvUsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_children(obj):\n",
        "    arr = list()\n",
        "\n",
        "    def separate(obj, arr):\n",
        "        \n",
        "        if isinstance(obj, dict):\n",
        "\n",
        "            for k, v in obj.items():\n",
        "              if k != 'children':\n",
        "                if isinstance(v, (dict, list)):\n",
        "                    separate(v, arr)\n",
        "                elif k == 'word':      \n",
        "                    arr.append(v)\n",
        "\n",
        "        elif isinstance(obj, list):\n",
        "            for item in obj:\n",
        "                separate(item, arr)\n",
        "         \n",
        "        return arr\n",
        "\n",
        "    results = separate(obj, arr)\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XYFHp-5KyQ7",
        "colab": {}
      },
      "source": [
        "def extract_constituents():\n",
        " modal = list()\n",
        " nounm = list()\n",
        " past = list() \n",
        " nounp = list()\n",
        " nouns = list()\n",
        "\n",
        " for key, value in prediction.items():\n",
        "  if (key=='hierplane_tree'):\n",
        "    for key, value in value.items():\n",
        "      if (key=='root'):\n",
        "        for key, value in value.items():\n",
        "          if (key == 'children'):\n",
        "\n",
        "            mod, pas, nou = extract_modal(value)\n",
        "            \n",
        "            for u in nou:\n",
        "              nu = simplify(u) \n",
        "              if nu not in nouns:\n",
        "                nouns.append(nu) \n",
        "\n",
        "            for m in mod:\n",
        "              md = simplify(m) # string gist\n",
        "              for nm in reversed(sorted(nouns,key=len)):  \n",
        "                if nm in md:   \n",
        "                  nounm.append(nm)\n",
        "                  nouns.remove(nm)\n",
        "             \n",
        "              for p in pas:\n",
        "                pa = simplify(p)\n",
        "      \n",
        "                if pa in md and len(md) > len(pa):\n",
        "                   if md.index(pa) == 0 :\n",
        "                     md = md.replace(pa,'')   \n",
        "                if md in pa and len(pa) > len(md):\n",
        "                   if pa.index(md) == 0 :\n",
        "                     pa = pa.replace(md,'')  \n",
        "                for np in reversed(sorted(nounp,key=len)):\n",
        "                  if np in pa and len(pa) > len(np): \n",
        "                    if pa.index(np) > 0 :\n",
        "                      pa = pa[0:pa.index(np)]\n",
        "                    else:\n",
        "                      pa = str(pa).replace(str(np),'')  \n",
        "                    nounp.append(np)\n",
        "                    nouns.remove(np)\n",
        "                if md in pa: # and len(pa) > len(md): # dont uncomment!\n",
        "                   if pa.index(md) > 0 :\n",
        "                     pa = pa[0:pa.index(md)]  \n",
        "                   else:\n",
        "                     pa = str(pa).replace(str(md),'')      \n",
        "                \n",
        "                if pa not in past:\n",
        "                  past.append(pa) \n",
        "              if md not in modal:        \n",
        "                modal.append(md) \n",
        "                \n",
        "              for p1 in past:\n",
        "                for p2 in past:\n",
        "                  if p2 in p1 and len(p1) > len(p2):\n",
        "                    past.remove(p2) \n",
        "              \n",
        "            return modal, past, nouns, nounm, nounp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6BHdEZXkTu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def simplify(constit):\n",
        "  gist = list();\n",
        "  sentence = set()  # rebuild with checking for overlap\n",
        "  for c in constit:\n",
        "      #print(c)\n",
        "      p = separate_children(c) # candidate phrases\n",
        "      #print(p)\n",
        "      for head in list(p):\n",
        "        #print(head)\n",
        "        phrase = word_tokenize(head)\n",
        "        #print(phrase)\n",
        "        words = set(phrase)\n",
        "        if len(sentence.intersection(words)) < len(words):\n",
        "          sentence.update(words)\n",
        "          gist.extend(phrase)\n",
        "  result = str()\n",
        "  for word in gist:\n",
        "    if word != '\\'ve' and word != 'n\\'t': # all exceptions\n",
        "      result = result + ' '\n",
        "    result = result + word  \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1fa97e20-1b5b-4cbb-d6ca-0775a5e185fa",
        "id": "mU94XoTgLOhu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"These distortions have seen one party or the other get shut out of general elections in recent years, including in contests they likely would have won if the parties had gotten to nominate a single candidate each.\"\n",
        "text.replace('\\\"','\\'')\n",
        "#print(text)\n",
        "\n",
        "prediction = predictor.predict(sentence=text)\n",
        "modal, past, nouns, nounm, nounp = extract_constituents()\n",
        "print(nouns)\n",
        "print(nounm)\n",
        "print(modal)\n",
        "print(past)\n",
        "print(nounp)\n",
        "\n",
        "mindex = int(0)\n",
        "pindex = int(0)\n",
        "length = int(0)\n",
        "\n",
        "try : \n",
        "  for m in modal:\n",
        "    if len(m) > mindex and m in text :\n",
        "      pindex = text.index(m)\n",
        "      mindex = text.index(m)\n",
        "      length = len(m)\n",
        "\n",
        "    for n in nounm:\n",
        "      if mindex > text.index(n):\n",
        "        mindex = text.index(n)  \n",
        "\n",
        "  print(text[mindex:pindex+length])\n",
        "\n",
        "  mindex = int(0)\n",
        "  pindex = int(0)\n",
        "  length = int(0)\n",
        "\n",
        "  for p in past:\n",
        "    if len(p) > pindex and p in text:\n",
        "      pindex = text.index(p)\n",
        "      mindex = text.index(p)\n",
        "      length = len(p) \n",
        "\n",
        "    for n in nounp:\n",
        "      if mindex > text.index(n):\n",
        "        mindex = text.index(n)\n",
        "      \n",
        "  print(text[mindex:pindex+length])    \n",
        "except ValueError:\n",
        "  print(mindex,pindex,length)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[[{'word': 'would', 'nodeType': 'MD', 'attributes': ['MD'], 'link': 'MD'}, {'word': 'have won if the parties had gotten to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'have', 'nodeType': 'VB', 'attributes': ['VB'], 'link': 'VB'}, {'word': 'won', 'nodeType': 'VBN', 'attributes': ['VBN'], 'link': 'VBN'}, {'word': 'if the parties had gotten to nominate a single candidate each', 'nodeType': 'SBAR', 'attributes': ['SBAR'], 'link': 'SBAR', 'children': [{'word': 'if', 'nodeType': 'IN', 'attributes': ['IN'], 'link': 'IN'}, {'word': 'the parties had gotten to nominate a single candidate each', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'the parties', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'the', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}, {'word': 'parties', 'nodeType': 'NNS', 'attributes': ['NNS'], 'link': 'NNS'}]}, {'word': 'had gotten to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'had', 'nodeType': 'VBD', 'attributes': ['VBD'], 'link': 'VBD'}, {'word': 'gotten to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'gotten', 'nodeType': 'VBN', 'attributes': ['VBN'], 'link': 'VBN'}, {'word': 'to nominate a single candidate each', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'to', 'nodeType': 'TO', 'attributes': ['TO'], 'link': 'TO'}, {'word': 'nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'nominate', 'nodeType': 'VB', 'attributes': ['VB'], 'link': 'VB'}, {'word': 'a single candidate each', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'a single candidate', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'a', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}, {'word': 'single', 'nodeType': 'JJ', 'attributes': ['JJ'], 'link': 'JJ'}, {'word': 'candidate', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}, {'word': 'each', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'each', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}]}]}]}]}]}]}]}]}]}]}], [{'word': 'if', 'nodeType': 'IN', 'attributes': ['IN'], 'link': 'IN'}, {'word': 'the parties had gotten to nominate a single candidate each', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'the parties', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'the', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}, {'word': 'parties', 'nodeType': 'NNS', 'attributes': ['NNS'], 'link': 'NNS'}]}, {'word': 'had gotten to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'had', 'nodeType': 'VBD', 'attributes': ['VBD'], 'link': 'VBD'}, {'word': 'gotten to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'gotten', 'nodeType': 'VBN', 'attributes': ['VBN'], 'link': 'VBN'}, {'word': 'to nominate a single candidate each', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'to', 'nodeType': 'TO', 'attributes': ['TO'], 'link': 'TO'}, {'word': 'nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'nominate', 'nodeType': 'VB', 'attributes': ['VB'], 'link': 'VB'}, {'word': 'a single candidate each', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'a single candidate', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'a', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}, {'word': 'single', 'nodeType': 'JJ', 'attributes': ['JJ'], 'link': 'JJ'}, {'word': 'candidate', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}, {'word': 'each', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'each', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}]}]}]}]}]}]}]}]}], [{'word': 'had', 'nodeType': 'VBD', 'attributes': ['VBD'], 'link': 'VBD'}, {'word': 'gotten to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'gotten', 'nodeType': 'VBN', 'attributes': ['VBN'], 'link': 'VBN'}, {'word': 'to nominate a single candidate each', 'nodeType': 'S', 'attributes': ['S'], 'link': 'S', 'children': [{'word': 'to nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'to', 'nodeType': 'TO', 'attributes': ['TO'], 'link': 'TO'}, {'word': 'nominate a single candidate each', 'nodeType': 'VP', 'attributes': ['VP'], 'link': 'VP', 'children': [{'word': 'nominate', 'nodeType': 'VB', 'attributes': ['VB'], 'link': 'VB'}, {'word': 'a single candidate each', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'a single candidate', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'a', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}, {'word': 'single', 'nodeType': 'JJ', 'attributes': ['JJ'], 'link': 'JJ'}, {'word': 'candidate', 'nodeType': 'NN', 'attributes': ['NN'], 'link': 'NN'}]}, {'word': 'each', 'nodeType': 'NP', 'attributes': ['NP'], 'link': 'NP', 'children': [{'word': 'each', 'nodeType': 'DT', 'attributes': ['DT'], 'link': 'DT'}]}]}]}]}]}]}]]\n",
            "[' These distortions', ' one party or the other', ' one party', ' the other', ' general elections', ' recent years', ' contests they likely would have won if the parties had gotten to nominate a single candidate each', ' contests', ' they']\n",
            "[' a single candidate each', ' a single candidate', ' the parties', ' each']\n",
            "[' would have won if the parties had gotten to nominate a single candidate each']\n",
            "[' if the parties had gotten to nominate a single candidate each']\n",
            "[]\n",
            " would have won if the parties had gotten to nominate a single candidate each\n",
            " if the parties had gotten to nominate a single candidate each\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHIQLmP3AnyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "prefix = '/content/'\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df = test_df.drop(index=0)\n",
        "  \n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1].replace(r'\\n', ' ', regex=True),\n",
        "    'past':''*test_df.shape[1],\n",
        "    'modal':''*test_df.shape[1],\n",
        "    'antecedent':''*test_df.shape[1],\n",
        "    'consequent':''*test_df.shape[1]\n",
        "})\n",
        "\n",
        "count = test_df['id'].count()\n",
        "print(count)\n",
        "\n",
        "for ind in tqdm(test_df.index): \n",
        "  prediction = predictor.predict(sentence=test_df['text'][ind])\n",
        "  modal, past, nouns, nounm, nounp = extract_constituents()\n",
        "  test_df['modal'][ind] = modal\n",
        "  test_df['past'][ind] = past\n",
        "\n",
        "  text = test_df['text'][ind]\n",
        "  mindex = int(0)\n",
        "  pindex = int(0)\n",
        "  length = int(0)\n",
        "\n",
        "  try : \n",
        "    for m in modal:\n",
        "      if len(m) > mindex and m in text :\n",
        "        pindex = text.index(m)\n",
        "        mindex = text.index(m)\n",
        "        length = len(m)\n",
        "\n",
        "      for n in nounm:\n",
        "        if mindex > text.index(n):\n",
        "          mindex = text.index(n) \n",
        "\n",
        "    test_df['consequent'][ind]=text[mindex:mindex+length]\n",
        "\n",
        "    mindex = int(0)\n",
        "    pindex = int(0)\n",
        "    length = int(0)\n",
        "\n",
        "    for p in past:\n",
        "      if len(p) > pindex and p in text:\n",
        "        pindex = text.index(p)\n",
        "        mindex = text.index(p)\n",
        "        length = len(p) \n",
        "\n",
        "      for n in nounp:\n",
        "        if mindex > text.index(n):\n",
        "          mindex = text.index(n)\n",
        "        \n",
        "    test_df['antecedent'][ind] = text[mindex:pindex+length]    \n",
        "  except ValueError:\n",
        "    print(mindex,pindex,length)\n",
        "\n",
        "  sleep(1)\n",
        "\n",
        "test_df.to_csv(prefix+'test.tsv', sep='\\t', index=False, header=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3w26wdnuriO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/test.tsv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}