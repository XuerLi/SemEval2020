{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnqA1JbeTGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/antecedents.tsv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/consequents.tsv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/simplified.tsv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.antecedents/submit_results.csv /content/antecedent_results.csv\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.consequents/submit_results.csv /content/consequent_results.csv\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.simplified/submit_results.csv /content/simplified_results.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHDDbRWsPd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1]\n",
        "})\n",
        "\n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUV4Wf4jjgv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xih_PEASjqro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer,BertForMaskedLM\n",
        "import torch\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "bertMaskedLM = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXEg697ylbCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score(sentence):\n",
        "    tokenize_input = tokenizer.tokenize(sentence)\n",
        "    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
        "    predictions=bertMaskedLM(tensor_input)\n",
        "    loss_fct = torch.nn.CrossEntropyLoss()\n",
        "    loss = loss_fct(predictions.squeeze(),tensor_input.squeeze()).data \n",
        "    return math.exp(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOIUK02YriCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get_score(\"If a few people get sick at a salad bar | wouldn't have happened\")\n",
        "get_score(\"in more careful people's shoes | wouldn't have happened\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbBm343LWeyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "a_df = pd.read_csv(prefix + 'antecedents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "a_df = pd.DataFrame({\n",
        "    'id': a_df[0],\n",
        "    'labels':a_df[1],\n",
        "    'text': a_df[2],\n",
        "    'start':a_df[3],\n",
        "    'end': a_df[4]\n",
        "})\n",
        "c_df = pd.read_csv(prefix + 'consequents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "c_df = pd.DataFrame({\n",
        "    'id': c_df[0],\n",
        "    'labels':c_df[1],\n",
        "    'text': c_df[2],\n",
        "    'start':c_df[3],\n",
        "    'end': c_df[4]\n",
        "})\n",
        "s_df = pd.read_csv(prefix + 'simplified.tsv', sep='\\t', delimiter=None, header=None)\n",
        "s_df = pd.DataFrame({\n",
        "    'id': s_df[0],\n",
        "    'labels':s_df[1],\n",
        "    'text': s_df[2]\n",
        "})\n",
        "\n",
        "rc_df = pd.read_csv(prefix + 'consequent_results.csv', header=None)\n",
        "rc_df = pd.DataFrame({\n",
        "    'id': rc_df[0],\n",
        "    'labels':rc_df[1]\n",
        "})\n",
        "ra_df = pd.read_csv(prefix + 'antecedent_results.csv', header=None)\n",
        "ra_df = pd.DataFrame({\n",
        "    'id': ra_df[0],\n",
        "    'labels':ra_df[1]\n",
        "})\n",
        "rs_df = pd.read_csv(prefix + 'simplified_results.csv', header=None)\n",
        "rs_df = pd.DataFrame({\n",
        "    'id': rs_df[0],\n",
        "    'labels':rs_df[1]\n",
        "})\n",
        "\n",
        "a_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CJ7g59uVvvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def guess(id, original, s_df):\n",
        "  antecedent =str()\n",
        "  consequent = str()\n",
        "  astart=-1\n",
        "  aend = -1\n",
        "  cstart=-1\n",
        "  cend = -1\n",
        "\n",
        "  srule = s_df.loc[s_df.id.str.contains(id)]\n",
        "  if len(srule) == 0:\n",
        "    print(id, 'not found')\n",
        "    return antecedent, astart, aend, consequent, cstart, cend  \n",
        "\n",
        "  slab = '0'\n",
        "  min = 10 # minimal reuired score on pre-trained transformer\n",
        "  print(id,' guessing...')\n",
        "  for s in srule.index: # s = index\n",
        "    sid = srule['id'][s]\n",
        "    stext = srule['text'][s]\n",
        "    score = get_score(stext)\n",
        "    if score < min :\n",
        "      min = score\n",
        "      if '|' in stext:\n",
        "        texts = stext.split('|')\n",
        "        if len(texts) > 0:\n",
        "          antecedent = texts[0]\n",
        "          if len(consequent) == 0 and len(texts) > 1 :\n",
        "            consequent = texts[1]\n",
        "                    \n",
        "  if len(antecedent) == 0 and '|' in text:\n",
        "    antecedent =  text.split('|')[0]\n",
        "\n",
        "  if len(consequent) == 0 and '|' in text and len(text.split('|')) > 1:\n",
        "    consequent =  text.split('|')[1]\n",
        "\n",
        "  print(id, antecedent,' | ', consequent)\n",
        "  \n",
        "  if len(antecedent) > 0:\n",
        "    if astart ==-1 or aend ==-1:\n",
        "      try:\n",
        "        astart = original.index(antecedent.rstrip())\n",
        "        if aend > astart:\n",
        "          antecedent = original[astart-1:aend]\n",
        "          print(id,' antecedent: '+antecedent)\n",
        "      except ValueError:\n",
        "        astart = 0\n",
        "        aend = 0\n",
        "        print(id, ValueError)\n",
        "        print(antecedent,'not in:\\n', original)\n",
        "    if aend ==-1:  \n",
        "      aend = astart + len(antecedent) \n",
        "  else:\n",
        "    print(id,' no antecedent')      \n",
        "        \n",
        "  if len(consequent) > 0 :\n",
        "    if cstart ==-1 or cend ==-1:\n",
        "      try:\n",
        "        cstart = original.index(consequent.rstrip())\n",
        "        if cend > cstart:\n",
        "          consequent = original[cstart-1,cend]\n",
        "          print(id,' consequent: '+consequent)  \n",
        "      except ValueError:\n",
        "        cstart = 0\n",
        "        cend = 0\n",
        "        print(id, ValueError)\n",
        "        print(consequent,'not in:\\n', original)\n",
        "    if cend ==-1:   \n",
        "      cend = cstart + len(consequent)\n",
        "  else:\n",
        "    print(id,' no consequent')\n",
        "\n",
        "  return antecedent, astart, aend, consequent, cstart, cend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDSx2bPhYBFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze(id, df, r_df):\n",
        "  atext = str()\n",
        "  astart = -1\n",
        "  aend = -1\n",
        "  arule = df.loc[df.id.str.contains(id)]\n",
        "  if len(arule) == 0:\n",
        "    print(id, ' missing')\n",
        "    return atext, astart, aend \n",
        "\n",
        "  # First check based on rules\n",
        "  alab ='0' # assume antecedent false\n",
        "  for a in arule.index: # [a] = index\n",
        "    amid = arule['id'][a]  \n",
        "    alab = arule['labels'][a] # rule\n",
        "    astart = arule['start'][a]\n",
        "    aend = arule['end'][a]\n",
        "    atext = arule['text'][a]\n",
        "    text = atext\n",
        "    #print(amid,'candidate ='+atext)\n",
        "    if alab == 1:\n",
        "      return atext, astart, aend\n",
        "\n",
        "    # If rules gave no certain \"yes\"(==1 above)\n",
        "    apred = r_df.loc[r_df.id.str.contains(amid)]\n",
        "    if len(apred) == 0:\n",
        "      print(amid, ' not predicted')\n",
        "      continue\n",
        "    for p in apred.index: # [p] = index\n",
        "      amid = apred['id'][p]  \n",
        "      alab = apred['labels'][p] # prediction\n",
        "      apredrule = df.loc[df.id.str.contains(amid)]\n",
        "      if len(apredrule) == 0:\n",
        "        print(amid, ' not found ')\n",
        "        continue\n",
        "      for i in apredrule.index:    \n",
        "        astart = apredrule['start'][i]\n",
        "        aend = apredrule['end'][i]\n",
        "        atext = apredrule['text'][i]\n",
        "        text = atext\n",
        "        #print(amid,'tried ='+atext)\n",
        "        if alab == 1: # if no prediction, pick last!\n",
        "          return atext, astart, aend\n",
        "  return atext, astart, aend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QUPpOr6t6udV",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "submit_df= pd.DataFrame(columns=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid'])\n",
        "\n",
        "for ind in tqdm(test_df.index): \n",
        "  original = test_df['text'][ind]\n",
        "  id = test_df['id'][ind]\n",
        "  print(id)\n",
        "\n",
        "  astart=-1\n",
        "  aend = -1\n",
        "  cstart=-1\n",
        "  cend = -1\n",
        "  text= str()\n",
        "  \n",
        "  antecedent, astart, aend = analyze(id, a_df, ra_df)\n",
        "  consequent, cstart, cend = analyze(id, c_df, rc_df)\n",
        "\n",
        "  if len(antecedent) > 0:\n",
        "    text = antecedent + ' | ' + consequent\n",
        "  else:\n",
        "    text = ' | ' + consequent\n",
        "\n",
        "  if len(text) == 0: # no antecedent or consequent\n",
        "    if len(srule) == 0:\n",
        "      print(id, 'simplified sentence is not available!')\n",
        "      continue\n",
        "    antecedent, astart, aend, consequent, cstart, cend = guess(id,original,s_df)  \n",
        "\n",
        "  if len(antecedent) > 0:\n",
        "    text = antecedent + ' | ' + consequent\n",
        "  else:\n",
        "    text = ' | ' + consequent\n",
        "\n",
        "\n",
        "  result_row = pd.Series( data={\n",
        "    'sentenceID': id,\n",
        "    'antecedent_startid':astart,\n",
        "    'antecedent_endid': aend,\n",
        "    'consequent_startid': cstart,\n",
        "    'consequent_endid': cend\n",
        "  }, name = str(id) )\n",
        "\n",
        "  submit_df = submit_df.append(result_row, ignore_index=True)\n",
        "\n",
        "  print(id, text, astart, aend, cstart, cend)\n",
        "  sleep(1)\n",
        "\n",
        "submit_df.to_csv(prefix+'subtask2.csv',index=False, header=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid']) \n",
        "submit_df.head() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib77s9dReMcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip submission_task2.zip subtask2.csv\n",
        "!mv /content/submission_task2.zip /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}