{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnqA1JbeTGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/train.csv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/antecedents.tsv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/consequents.tsv /content\n",
        "#!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/simplified.tsv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.antecedents/submit_results.csv /content/antecedent_results.csv\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.consequents/submit_results.csv /content/consequent_results.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHDDbRWsPd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1]\n",
        "})\n",
        "\n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbBm343LWeyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "a_df = pd.read_csv(prefix + 'antecedents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "a_df = pd.DataFrame({\n",
        "    'id': a_df[0],\n",
        "    'labels':a_df[1],\n",
        "    'text': a_df[2],\n",
        "    'start':a_df[3],\n",
        "    'end': a_df[4]\n",
        "})\n",
        "c_df = pd.read_csv(prefix + 'consequents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "c_df = pd.DataFrame({\n",
        "    'id': c_df[0],\n",
        "    'labels':c_df[1],\n",
        "    'text': c_df[2],\n",
        "    'start':c_df[3],\n",
        "    'end': c_df[4]\n",
        "})\n",
        "\n",
        "rc_df = pd.read_csv(prefix + 'consequent_results.csv', header=None)\n",
        "rc_df = pd.DataFrame({\n",
        "    'id': rc_df[0],\n",
        "    'labels':rc_df[1]\n",
        "})\n",
        "ra_df = pd.read_csv(prefix + 'antecedent_results.csv', header=None)\n",
        "ra_df = pd.DataFrame({\n",
        "    'id': ra_df[0],\n",
        "    'labels':ra_df[1]\n",
        "})\n",
        "\n",
        "a_df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8X5DmJxNUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install allennlp==1.0.0rc1 allennlp-models==1.0.0rc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAzLpie_9b9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.syntax.biaffine_dependency_parser\n",
        "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/biaffine-dependency-parser-ptb-2020.04.06.tar.gz\")\n",
        "\n",
        "prediction = predictor.predict(\n",
        "  sentence=\"When I ask Robertson if any of the tests offered by Theranos could have saved Holmes's uncle, he takes a long pause.\"\n",
        ")\n",
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze1FUy-yukEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_dependents(prediction):\n",
        " for k, v in prediction.items():\n",
        "  if (k=='hierplane_tree'):\n",
        "    for ke, val in v.items():\n",
        "      if (ke=='root'):\n",
        "        for key, value in val.items():\n",
        "          if (key == 'children'):\n",
        "            return extract_children(value) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rrhac-EvZsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_children(obj):\n",
        "  arr = list()\n",
        "  deps = list()\n",
        "  spans = list()\n",
        "\n",
        "  def extract(obj, arr): \n",
        "    if isinstance(obj, dict):\n",
        "      for k, v in obj.items():\n",
        "        if isinstance(v, (dict, list)):\n",
        "          extract(v, arr)     \n",
        "        if k=='word':\n",
        "          arr.append(v)\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "      for item in obj:\n",
        "        if isinstance(item, dict):\n",
        "    \n",
        "          for key, value in item.items():\n",
        "            if key =='spans' and len(value) > 0:\n",
        "              spans.append(value)\n",
        "            if key =='children':\n",
        "              deps.append(value)  \n",
        "            #if key =='attributes' and 'VERB' in value:\n",
        "            #  deps.append(item)\n",
        "        \n",
        "        extract(item, arr)\n",
        "      \n",
        "    return arr\n",
        "\n",
        "  words = extract(obj, arr)\n",
        "  return words, spans, deps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rZCHjnohcfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stringnify(dependent):\n",
        "  clauses = list()\n",
        " \n",
        "  for d in dependent:\n",
        "    c = separate_children(d) # list of d['word']s\n",
        "    print(c)\n",
        "    clauses.append(c)\n",
        "\n",
        "  return clauses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep8OBDtqgyE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_children(obj):\n",
        "  arr = list()\n",
        "\n",
        "  def separate(obj, arr): \n",
        "    if isinstance(obj, dict):\n",
        "\n",
        "      for k, v in obj.items():\n",
        "        if k != 'children':\n",
        "          if isinstance(v, (dict, list)):\n",
        "              separate(v, arr)\n",
        "          elif k == 'word':      \n",
        "              arr.append(v)\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "        for item in obj:\n",
        "            separate(item, arr)\n",
        "      \n",
        "    return arr\n",
        "\n",
        "  results = separate(obj, arr)\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJQJNkGXQp-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words, spans, deps = extract_dependents(prediction)\n",
        "print(words)\n",
        "print(spans)\n",
        "print(deps)\n",
        "\n",
        "for dep in deps:\n",
        "  clauses = stringnify(dep)\n",
        "  print(clauses)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDSx2bPhYBFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze(id, df, r_df):\n",
        "  atext = str()\n",
        "  astart = -1\n",
        "  aend = -1\n",
        "  arule = df.loc[df.id.str.contains(id)]\n",
        "  if len(arule) == 0:\n",
        "    return id, 0, atext, astart, aend, 0\n",
        "\n",
        "  # First check based on rules\n",
        "  #print(id,len(arule.index))\n",
        "  \n",
        "  alab ='0' # assume antecedent false\n",
        "  count= 0  # counter of arules\n",
        "  for a in arule.index: # [a] = index\n",
        "    count = count + 1\n",
        "    amid = arule['id'][a]  \n",
        "    alab = arule['labels'][a] # rule\n",
        "    astart = arule['start'][a]\n",
        "    aend = arule['end'][a]\n",
        "    atext = arule['text'][a]\n",
        "    text = atext\n",
        "    #print(amid,'candidate ='+atext)\n",
        "    if alab == 1:\n",
        "      return amid, alab, atext, astart, aend, 100 # positive!\n",
        "\n",
        "    # If rules gave no certain \"yes\"(==1 above)\n",
        "    apred = r_df.loc[r_df.id.str.contains(amid)]\n",
        "    if len(apred) == 0:\n",
        "      print(amid, ' not predicted')\n",
        "      continue\n",
        "    for p in apred.index: # [p] = index\n",
        "      amid = apred['id'][p]  \n",
        "      alab = apred['labels'][p] # prediction\n",
        "      apredrule = df.loc[df.id.str.contains(amid)]\n",
        "      if len(apredrule) == 0:\n",
        "        print(amid, ' not found ')\n",
        "        continue\n",
        "      for i in apredrule.index:    \n",
        "        astart = apredrule['start'][i]\n",
        "        aend = apredrule['end'][i]\n",
        "        atext = apredrule['text'][i]\n",
        "        text = atext\n",
        "        #print(a,amid,alab,atext)\n",
        "        if alab == 1:\n",
        "          if len(arule.index) > count:\n",
        "            return amid, alab, atext, astart, aend, 10*count # uncertain\n",
        "          return amid, alab, atext, astart, aend, 75 # certain       \n",
        "  return amid, alab, atext, astart, aend, 25 # unpredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QUPpOr6t6udV",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "submit_df = pd.DataFrame(columns=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid'])\n",
        "report_df = pd.DataFrame(columns=['sentenceID','clabel','cprob','consequent','cstart','cend','gold_consequent','alabel','aprob','antecedent','astart','aend','gold_antecedent'])\n",
        "\n",
        "for ind in tqdm(test_df.index): \n",
        "  original = test_df['text'][ind]\n",
        "  id = test_df['id'][ind]\n",
        "  #print(id)\n",
        "\n",
        "  astart=-1\n",
        "  aend = -1\n",
        "  cstart=-1\n",
        "  cend = -1\n",
        "  text= str()\n",
        "  \n",
        "  aid, alab, antecedent, astart, aend, aprob = analyze(id, a_df, ra_df)\n",
        "  cid, clab, consequent, cstart, cend, cprob = analyze(id, c_df, rc_df)\n",
        "\n",
        "  if len(antecedent) > 0:\n",
        "    text = antecedent      \n",
        "  if len(consequent) > 0 and not (consequent in text):\n",
        "    text = text + ' | ' + consequent\n",
        "  elif len(text) > 0:\n",
        "    astart= cstart\n",
        "    aend = cend \n",
        "    consequent = '{}'\n",
        "    cstart=-1\n",
        "    cend = -1 \n",
        "  else:\n",
        "    print(id,'no result')\n",
        "    continue\n",
        "\n",
        "  report_row = pd.Series( data={\n",
        "    'sentenceID': id,\n",
        "    'clabel': clab,\n",
        "    'cprob': cprob,\n",
        "    'consequent': consequent, # comment out gold_,\n",
        "    'cstart': cstart,\n",
        "    'cend': cend,\n",
        "    #'gold_consequent': test_df['consequent'][ind],\n",
        "    'alabel': alab,\n",
        "    'aprob': aprob,\n",
        "    'antecedent': antecedent, \n",
        "    'astart': astart,\n",
        "    'aend': aend,\n",
        "    #'gold_antecedent': test_df['antecedent'][ind]\n",
        "  }, name = str(id) )\n",
        "\n",
        "  result_row = pd.Series( data={\n",
        "    'sentenceID': id,\n",
        "    'antecedent_startid':astart,\n",
        "    'antecedent_endid': aend,\n",
        "    'consequent_startid': cstart,\n",
        "    'consequent_endid': cend\n",
        "  }, name = str(id) )\n",
        "\n",
        "  submit_df = submit_df.append(result_row, ignore_index=True)\n",
        "  report_df = report_df.append(report_row, ignore_index=True)\n",
        "\n",
        "  #print(id, text, astart, aend, cstart, cend)\n",
        "  sleep(1)\n",
        "\n",
        "submit_df.to_csv(prefix+'subtask2.csv',index=False, header=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid']) \n",
        "report_df.to_csv(prefix+'report.csv',index=False, header=['sentenceID','clabel','cprob','consequent','cstart','cend','gold_consequent','alabel','aprob','antecedent','astart','aend','gold_antecedent'])\n",
        "report_df.head(100) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib77s9dReMcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip submission_task2.zip subtask2.csv\n",
        "!mv /content/submission_task2.zip /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/\n",
        "!mv /content/report.csv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}