{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnqA1JbeTGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/antecedents.tsv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/consequents.tsv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/simplified.tsv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/antecedents/submit_results.csv /content/antecedent_results.csv\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/consequents/submit_results.csv /content/consequent_results.csv\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/simplified/submit_results.csv /content/simplified_results.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHDDbRWsPd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "test_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1].replace(r'[,;:#&()`\\'\\\"]', '', regex=True)\n",
        "})\n",
        "\n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUV4Wf4jjgv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pytorch_pretrained_bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xih_PEASjqro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_pretrained_bert import BertTokenizer,BertForMaskedLM\n",
        "import torch\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "bertMaskedLM = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXEg697ylbCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_score(sentence):\n",
        "    tokenize_input = tokenizer.tokenize(sentence)\n",
        "    tensor_input = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
        "    predictions=bertMaskedLM(tensor_input)\n",
        "    loss_fct = torch.nn.CrossEntropyLoss()\n",
        "    loss = loss_fct(predictions.squeeze(),tensor_input.squeeze()).data \n",
        "    return math.exp(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbBm343LWeyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "a_df = pd.read_csv(prefix + 'antecedents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "a_df = pd.DataFrame({\n",
        "    'id': a_df[0],\n",
        "    'labels':a_df[1],\n",
        "    'text': a_df[2].replace(r'[,;:#&()`\\'\\\"]', '', regex=True)\n",
        "})\n",
        "c_df = pd.read_csv(prefix + 'consequents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "c_df = pd.DataFrame({\n",
        "    'id': c_df[0],\n",
        "    'labels':c_df[1],\n",
        "    'text': c_df[2].replace(r'[,;:#&()`\\'\\\"]', '', regex=True)\n",
        "})\n",
        "s_df = pd.read_csv(prefix + 'simplified.tsv', sep='\\t', delimiter=None, header=None)\n",
        "s_df = pd.DataFrame({\n",
        "    'id': s_df[0],\n",
        "    'labels':s_df[1],\n",
        "    'text': s_df[2].replace(r'[,;:#&()`\\'\\\"]', '', regex=True)\n",
        "})\n",
        "\n",
        "rc_df = pd.read_csv(prefix + 'consequent_results.csv', header=None)\n",
        "rc_df = pd.DataFrame({\n",
        "    'id': rc_df[0],\n",
        "    'labels':rc_df[1]\n",
        "})\n",
        "ra_df = pd.read_csv(prefix + 'antecedent_results.csv', header=None)\n",
        "ra_df = pd.DataFrame({\n",
        "    'id': ra_df[0],\n",
        "    'labels':ra_df[1]\n",
        "})\n",
        "rs_df = pd.read_csv(prefix + 'simplified_results.csv', header=None)\n",
        "rs_df = pd.DataFrame({\n",
        "    'id': rs_df[0],\n",
        "    'labels':rs_df[1]\n",
        "})\n",
        "\n",
        "s_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QUPpOr6t6udV",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "submit_df= pd.DataFrame(columns=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid'])\n",
        "t=0\n",
        "for ind in tqdm(test_df.index): \n",
        "  original = test_df['text'][ind]\n",
        "  id = test_df['id'][ind]\n",
        "  #print(id, original)\n",
        "  \n",
        "  modela = ra_df.loc[ra_df.id.str.contains(id)]\n",
        "  modelc = rc_df.loc[rc_df.id.str.contains(id)]\n",
        "  models = rs_df.loc[rs_df.id.str.contains(id)]\n",
        "\n",
        "  antecedent = str()\n",
        "  consequent = str()\n",
        "  text= str()\n",
        "  alab ='0' # assume no\n",
        "  for a in modela.index:\n",
        "    amid = modela['id'][a]  \n",
        "    alab = modela['labels'][a]\n",
        "    if alab == 1:\n",
        "      #print(amid)\n",
        "      antecd = a_df.loc[a_df.id.str.contains(amid)]\n",
        "      assert antecd['id'].count() == 1 # 1-to-1\n",
        "      for i in antecd.index:\n",
        "        atext = antecd['text'][i]\n",
        "        antecedent = atext\n",
        "        text = atext\n",
        "\n",
        "  clab = '0'\n",
        "  for c in modelc.index:\n",
        "    cmid = modelc['id'][c]  \n",
        "    clab = modelc['labels'][c]\n",
        "    if clab == 1: \n",
        "      #print(cmid) \n",
        "      conseq = c_df.loc[c_df.id.str.contains(cmid)]\n",
        "      assert conseq['id'].count() == 1 # 1-to-1\n",
        "      for i in conseq.index:\n",
        "        consequent = conseq['text'][i]\n",
        "        if len(antecedent) > 0:\n",
        "          text = antecedent + ' ' + consequent\n",
        "        else:\n",
        "          text = consequent  \n",
        "     \n",
        "  if len(text) == 0:\n",
        "    slab = '0'\n",
        "    for s in models.index:\n",
        "      smid = models['id'][s]\n",
        "      slab = models['labels'][s]\n",
        "      if slab == 1:\n",
        "        #print(smid)\n",
        "        simple = s_df.loc[s_df.id.str.contains(smid)]\n",
        "        assert simple['id'].count() == 1 # 1-to-1\n",
        "        for i in simple.index:\n",
        "          stext = simple['text'][i]\n",
        "          text = stext                \n",
        "      \n",
        "  minis = 1000\n",
        "  if len(text) == 0 or text == consequent: # guess antesedent\n",
        "    #print('guessing...')\n",
        "    for s in models.index:\n",
        "      smid = models['id'][s]\n",
        "      simple = s_df.loc[s_df.id.str.contains(smid)]\n",
        "      assert simple['id'].count() == 1 # 1-to-1    \n",
        "      for i in simple.index:\n",
        "        sid = simple['id'][i]\n",
        "        stext = simple['text'][i]\n",
        "        stext = stext.lstrip() \n",
        "        stext = stext.rstrip()\n",
        "        stext = stext.replace('   ',' ')\n",
        "        score = get_score(stext)\n",
        "        if score < minis :\n",
        "          minis = score\n",
        "          if '|' in stext:\n",
        "            texts = stext.split('|')\n",
        "            if len(texts) > 0:\n",
        "              antecedent = texts[0]\n",
        "              if len(consequent) == 0 and len(texts) > 1 :\n",
        "                consequent = texts[1]\n",
        "              \n",
        "                          \n",
        "  if len(antecedent) == 0 and '|' in text:\n",
        "    antecedent =  text.split('|')[0]\n",
        "\n",
        "  if len(consequent) == 0 and '|' in text and len(text.split('|')) > 1:\n",
        "    consequent =  text.split('|')[1]\n",
        "\n",
        "  antecedent = antecedent.lstrip()\n",
        "  antecedent = antecedent.rstrip()\n",
        "  consequent = consequent.lstrip()\n",
        "  consequent = consequent.rstrip()\n",
        "  antecedent = antecedent.replace(' \\'s','\\'s')\n",
        "  antecedent = antecedent.replace(' \\'d','\\'d')\n",
        "  consequent = consequent.replace(' \\'s','\\'s')\n",
        "  consequent = consequent.replace(' \\'d','\\'d')\n",
        "  consequent = consequent.replace('$ ','$')\n",
        "  antecedent = antecedent.replace('$ ','$')\n",
        "  consequent = consequent.replace(' %','%')\n",
        "  antecedent = antecedent.replace(' %','%')\n",
        "  consequent = consequent.replace('/ ','/')\n",
        "  antecedent = antecedent.replace('/ ','/')\n",
        "  consequent = consequent.replace(' /','/')\n",
        "  antecedent = antecedent.replace(' /','/')\n",
        "  consequent = consequent.replace(' -','-')\n",
        "  antecedent = antecedent.replace(' -','-')\n",
        "  #consequent = consequent.replace('- ','-')\n",
        "  #antecedent = antecedent.replace('- ','-')\n",
        "  consequent = consequent.replace(' .','.')\n",
        "  antecedent = antecedent.replace(' .','.')\n",
        "  consequent = consequent.replace(' ;',';')\n",
        "  antecedent = antecedent.replace(' ;',';')\n",
        "  antecedent = antecedent.replace(' \\'nt','\\'nt')\n",
        "  consequent = consequent.replace(' \\'nt','\\'nt')\n",
        "  antecedent = antecedent.replace('it s','its')\n",
        "  consequent = consequent.replace('it s','its')\n",
        "  antecedent = antecedent.replace('   ',' ')\n",
        "  consequent = consequent.replace('   ',' ')\n",
        "  antecedent = antecedent.replace('  ',' ')\n",
        "  consequent = consequent.replace('  ',' ')\n",
        "  #print(antecedent, consequent)\n",
        "  astart =-1\n",
        "  aend = -1\n",
        "  cstart = -1\n",
        "  cend = -1\n",
        "\n",
        "  if len(antecedent) > 0 :\n",
        "    try:\n",
        "      astart = original.index(antecedent[0:15])\n",
        "    except:\n",
        "      print(id, original, antecedent)\n",
        "    aend = astart + len(antecedent)\n",
        "\n",
        "  if len(consequent) > 0 :\n",
        "    try:\n",
        "      cstart = original.index(consequent[0:15])\n",
        "    except:\n",
        "      print(id, original, consequent)     \n",
        "    cend = cstart + len(consequent)\n",
        "\n",
        "  result_row = pd.Series( data={\n",
        "    'sentenceID': id,\n",
        "    'antecedent_startid':astart,\n",
        "    'antecedent_endid': aend,\n",
        "    'consequent_startid': cstart,\n",
        "    'consequent_endid': cend\n",
        "  })\n",
        "\n",
        "  submit_df = submit_df.append(result_row, ignore_index=True)\n",
        "  t= t+1\n",
        "\n",
        "  sleep(1)\n",
        "\n",
        "submit_df.to_csv(prefix+'subtask2.csv',index=False, header=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid'])  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-V9U4MxtS88",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "submit_df.to_csv(prefix+'subtask2.csv',index=False)  \n",
        "submit_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib77s9dReMcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip submission_task2.zip subtask2.csv\n",
        "!mv /content/submission_task2.zip /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}