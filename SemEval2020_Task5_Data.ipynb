{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SemEval2020_Task5_Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMnqA1JbeTGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/test.csv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/train.csv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/antecedents.tsv /content\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/consequents.tsv /content\n",
        "#!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/simplified.tsv /content\n",
        "\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.antecedents/submit_results.csv /content/antecedent_results.csv\n",
        "!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/outputs.consequents/submit_results.csv /content/consequent_results.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsHDDbRWsPd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "test_df = pd.read_csv(prefix + 'train.csv', header=None) # change to test.csv\n",
        "test_df=test_df.drop(index=0)\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'id':test_df[0],\n",
        "    'text': test_df[1], # comment out following for test.csv\n",
        "    'antecedent': test_df[2],\n",
        "    'consequent': test_df[3],\n",
        "    'astart':test_df[4],\n",
        "    'aend':test_df[5],\n",
        "    'cstart':test_df[6],\n",
        "    'cend':test_df[7]\n",
        "})\n",
        "\n",
        "# display \n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbBm343LWeyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "a_df = pd.read_csv(prefix + 'antecedents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "a_df = pd.DataFrame({\n",
        "    'id': a_df[0],\n",
        "    'labels':a_df[1],\n",
        "    'text': a_df[2],\n",
        "    'start':a_df[3],\n",
        "    'end': a_df[4]\n",
        "})\n",
        "a_df.sort_values(by=['id','text'], ascending=[1,0])\n",
        "\n",
        "c_df = pd.read_csv(prefix + 'consequents.tsv', sep='\\t', delimiter=None, header=None)\n",
        "c_df = pd.DataFrame({\n",
        "    'id': c_df[0],\n",
        "    'labels':c_df[1],\n",
        "    'text': c_df[2],\n",
        "    'start':c_df[3],\n",
        "    'end': c_df[4]\n",
        "})\n",
        "\n",
        "rc_df = pd.read_csv(prefix + 'consequent_results.csv', header=None)\n",
        "rc_df = pd.DataFrame({\n",
        "    'id': rc_df[0],\n",
        "    'labels':rc_df[1]\n",
        "})\n",
        "ra_df = pd.read_csv(prefix + 'antecedent_results.csv', header=None)\n",
        "ra_df = pd.DataFrame({\n",
        "    'id': ra_df[0],\n",
        "    'labels':ra_df[1]\n",
        "})\n",
        "\n",
        "a_df.head(30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO8X5DmJxNUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install allennlp==1.0.0rc4 allennlp-models==1.0.0rc4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAzLpie_9b9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.syntax.biaffine_dependency_parser\n",
        "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/biaffine-dependency-parser-ptb-2020.04.06.tar.gz\")\n",
        "\n",
        "original = \"When they tested a strategy that sold stocks and went into cash every time price-to-dividend multiples went clearly above their historic mean at the time, and re-entered when they had become cheap, in 20 different countries, they found that in all of them it would have been better simply to buy and hold stocks.\"    \n",
        "prediction = predictor.predict(\n",
        "  sentence = original\n",
        ")\n",
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze1FUy-yukEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_dependents(prediction):\n",
        " root = None\n",
        " text = str()\n",
        "\n",
        " for k, v in prediction.items():\n",
        "  if (k=='hierplane_tree'):\n",
        "    for key, val in v.items():\n",
        "      if key=='root':\n",
        "        root = val\n",
        "      if key=='text': \n",
        "        text = val   \n",
        "\n",
        " root.update({'text': text})\n",
        " return extract_children(root) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rrhac-EvZsE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_children(obj, include='', exclude=''):\n",
        "  arr = list()\n",
        "  deps = list()\n",
        "  spans = list()\n",
        "  verbs = list()\n",
        "\n",
        "  def extract(obj, arr): \n",
        "    explore = False\n",
        "    limit = 5 \n",
        "    count = 0\n",
        "    text = str()\n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "      for k, v in obj.items():\n",
        "        if include =='' and k=='attributes' and ('VERB' in v or 'AUX' in v or 'PROPN' in v or 'NOUN' in v or 'PREP' in v):\n",
        "          if obj not in verbs:\n",
        "            verbs.append(obj)\n",
        "\n",
        "        if k=='nodeType':\n",
        "          arr.append(v)\n",
        "\n",
        "        if k=='text' and len(v) > 0 and len(text) == 0:  \n",
        "          text = v\n",
        "\n",
        "        if isinstance(v, (dict, list)):\n",
        "          if count < limit:\n",
        "            count = count + 1\n",
        "            extract(v, arr) # children   \n",
        "             \n",
        "    elif isinstance(obj, list):\n",
        "      for item in obj:\n",
        "        if isinstance(item, dict):\n",
        "    \n",
        "          for key, value in item.items():\n",
        "            if key == 'nodeType':\n",
        "              if (include=='' or value in include) and (exclude=='' or not [v for v in arr if v in exclude]):\n",
        "                #print(include, exclude, item)\n",
        "                if item not in deps: \n",
        "                  deps.append(item) # child\n",
        "                explore = True \n",
        "              else:  \n",
        "                explore = False\n",
        "\n",
        "            if include=='' and key=='attributes' and ('VERB' in value or 'AUX' in value or 'PROPN' in value or 'NOUN' in value or 'PREP' in value):\n",
        "              explore = True \n",
        "            elif key=='attributes' and 'CCONJ' in value:\n",
        "              explore = False     \n",
        "\n",
        "            if explore and key =='spans':\n",
        "              if value not in spans:\n",
        "                spans.append(value)  \n",
        "            \n",
        "          if explore and count < limit:\n",
        "            count = count + 1\n",
        "            extract(item, arr) \n",
        "         \n",
        "    return text\n",
        "\n",
        "  text = extract(obj, arr)\n",
        "  return text, spans, deps, verbs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J6ueg9eJ4RB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def position(span):\n",
        "  return span[0]['start']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep8OBDtqgyE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def follow_children(obj):\n",
        "  arr = list()\n",
        "\n",
        "  def follow(obj, arr): \n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "      for k, v in obj.items():\n",
        "        if k == 'children':      \n",
        "          follow(v, arr)\n",
        "\n",
        "    elif isinstance(obj, list):\n",
        "      for item in obj:\n",
        "        if isinstance(item, dict):\n",
        "          for key, value in item.items():\n",
        "            if key =='attributes' and ('VERB' in value or 'AUX' in value or 'PROPN' in value or 'NOUN' in value or 'PREP' in value):\n",
        "              arr.append(item)\n",
        "\n",
        "          follow(item, arr)\n",
        "      \n",
        "    return arr\n",
        "\n",
        "  results = follow(obj, arr)\n",
        "  return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c45HuHKFl-Ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "regex = '\\\\\\'\\s+([^\\']+)\\s+\\\\\\''\n",
        "def compact(fragment):\n",
        "# specify the number of replacements by changing the 4th argument\n",
        "  result = re.sub(regex, '\\''+r'\\1'+'\\'' , fragment)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CoPtjXKBtrj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(fragment):\n",
        "  r = fragment.strip()\n",
        "  r = compact(r)\n",
        "  r = r.replace('   ',' ') \n",
        "  r = r.replace('  ',' ')\n",
        "  r = r.replace(' ,',',') \n",
        "  r = r.replace(' .','.')\n",
        "  r = r.replace('Mr.','Mr. ')\n",
        "  r = r.replace('Ms.','Ms. ')\n",
        "  r = r.replace('Mrs.','Mrs. ')\n",
        "  r = r.replace('.  ','. ') # Mr./Ms./Mrs.\n",
        "  r = r.replace('... ','...')\n",
        "  r = r.replace(' --- ','---')\n",
        "  r = r.replace(' -- ','--')\n",
        "  r = r.replace(' - ','-')\n",
        "  r = r.replace(' !','!')\n",
        "  r = r.replace(' ?','?')\n",
        "  r = r.replace('$ ','$')\n",
        "  r = r.replace('# ','#')\n",
        "  r = r.replace(' %','%')\n",
        "  r = r.replace('( ','(')\n",
        "  r = r.replace(' )',')')\n",
        "  r = r.replace(' ;',';')\n",
        "  r = r.replace(' :',':') \n",
        "  r = r.replace(': ',':') #50/50 - carefull!\n",
        "  r = r.replace(' nt','nt')\n",
        "  r = r.replace(' (k)','(k)') #401(k)\n",
        "  r = r.replace(' (tm)','(tm)')\n",
        "  r = r.replace('n na ','nna ')\n",
        "  r = r.replace(' \\'m ','\\'m ')\n",
        "  r = r.replace('s \\' ','s\\' ') # was 'neurtralized'?\n",
        "  r = r.replace(' \\'s ','\\'s ') # a 'surgical' strike!\n",
        "  r = r.replace(' \\'d ','\\'d ')\n",
        "  r = r.replace(' \\'re ','\\'re ')\n",
        "  r = r.replace(' \\'ve ','\\'ve ')\n",
        "  r = r.replace(' \\'ll ','\\'ll ')\n",
        "  r = r.replace(' n\\'t','n\\'t') # what about UPPER()?\n",
        "  r = r.replace(' \\' ',' \\'')\n",
        "  r = r.rstrip()\n",
        "  return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAy762nn4sJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def explore(verb, condition, complement, sentence, include='',exclude=''):\n",
        "    deps = list()\n",
        "    loops= list()\n",
        "    if len(condition)==0:\n",
        "      return deps, loops\n",
        "\n",
        "    begin = sentence.find(condition) # superspan for condition\n",
        "    if begin ==-1: \n",
        "      #print(condition,' not in:\\n'+sentence)\n",
        "      return deps, loops\n",
        "    stop = begin + 1 + len(condition) \n",
        "\n",
        "    if len(complement) > 0:\n",
        "      index = sentence.find(complement) # superspan for complement\n",
        "      if index ==-1: \n",
        "        #print(complement,' not in:\\n'+sentence)\n",
        "        return deps,loops\n",
        "      if begin < index and index < stop: \n",
        "        #print(complement,'<-->'+condition,' in:\\n'+sentence)\n",
        "        loops.append(complement)\n",
        "        deps.append(condition)   \n",
        "      elif index == stop:  \n",
        "        #print(complement,' + '+condition)\n",
        "        stop = stop + 1 + len(complement)\n",
        "        loops.append(complement)\n",
        "      #elif index > stop:\n",
        "      #  stop = index \n",
        "      #  condition = sentence[begin:stop]\n",
        "\n",
        "    word = verb['word']\n",
        "    #print( word ,'-->', condition)\n",
        "    subtext, subspans, subjs, subverbs = extract_children(verb, include, exclude)\n",
        "    if len(subspans) == 0:\n",
        "      return deps, loops\n",
        "\n",
        "    for sub in subjs:    \n",
        "      descendant = sub['word']\n",
        "      #print(word, begin, '\\\"'+descendant+'\\\"', stop) \n",
        "      for span in sorted(subspans,key=position): # all subspans\n",
        "        start=span[0]['start']\n",
        "        end = span[0]['end']\n",
        "        #print(start, sentence[start:end], begin, stop)\n",
        "        if begin <= start and start <= stop: # span of the condition\n",
        "          if start > 2: start = start - 2 # due to some unknown issue\n",
        "          spantext = sentence[start:end].strip()\n",
        "          #print(spantext, start, condition, end)\n",
        "          if len(spantext) > 0:\n",
        "            if spantext in condition:\n",
        "              if spantext not in deps:\n",
        "                deps.append(spantext)   \n",
        "            if spantext in complement:\n",
        "              if spantext not in loops: \n",
        "                loops.append(spantext)  \n",
        "\n",
        "    return deps, loops       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bmabbq-MUbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def track(verbs, antecedent, consequent, sentence):\n",
        "  adeps = set()\n",
        "  aloops= set()\n",
        "  cdeps = set()\n",
        "  cloops= set()\n",
        "  if len(verbs)==0:\n",
        "    print('no verbs!')\n",
        "    return adeps, cdeps, aloops, cloops\n",
        "\n",
        "  for verb in verbs: # any 'VERB' or \"AUX\" (Why ?)\n",
        "    deps, loops = explore(verb, antecedent, consequent, sentence, 'dep nsubj','cc advcl')\n",
        "    adeps.update(deps)\n",
        "    aloops.update(loops)\n",
        "    deps, loops = explore(verb, consequent, antecedent, sentence, 'dep prep advmod aux','xcomp')\n",
        "    cdeps.update(deps)\n",
        "    cloops.update(loops)\n",
        "    if len(adeps) > 0 and len(cdeps) > 0:\n",
        "      return adeps, cdeps, aloops, cloops    \n",
        "    adeps = set()\n",
        "    cdeps = set()  \n",
        "\n",
        "  return adeps, cdeps, aloops, cloops   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBfvzUf-StyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_from(md, pa):\n",
        "  index = -1\n",
        "  if pa in md and len(md) > len(pa):\n",
        "    index = md.find(pa)\n",
        "    if index > 0 :\n",
        "      md = md[0:index]\n",
        "      #print('|'+md+'{...}')\n",
        "    elif index == 0:\n",
        "      md = md.replace(pa,'')\n",
        "      #print('|{...}'+md)  \n",
        "  return md, index       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDSx2bPhYBFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analyze(id, df, r_df, sentence, verbs=[], ctext='', first=True):\n",
        "  atext = str()\n",
        "  astart = -1\n",
        "  aend = -1\n",
        "  arule = df.loc[df.id.str.contains(id)]\n",
        "  if len(arule) == 0:\n",
        "    return id, 0, atext, astart, aend, 0\n",
        "\n",
        "  print('|',ctext)\n",
        "  # First check based on rules\n",
        "  #print(id,len(arule.index))\n",
        "  alab ='0' # assume antecedent false\n",
        "  count= 0  # counter of arules\n",
        "  for a in arule.index: # [a] = index\n",
        "    count = count + 1\n",
        "    amid = arule['id'][a]  \n",
        "    alab = arule['labels'][a] # rule\n",
        "    astart = arule['start'][a]\n",
        "    aend = arule['end'][a]\n",
        "    atext = arule['text'][a]\n",
        "    text = atext\n",
        "    #print(amid,'candidate ='+atext)\n",
        "    if alab == 1:\n",
        "      print('v' , atext)\n",
        "      return amid, alab, atext, astart, aend, 100 # positive!\n",
        "\n",
        "    # If rules gave no certain \"yes\"(==1 above)\n",
        "    apred = r_df.loc[r_df.id.str.contains(amid)]\n",
        "    if len(apred) == 0:\n",
        "      print(amid, ' not predicted')\n",
        "      continue\n",
        "    for p in apred.index: # [p] = index\n",
        "      amid = apred['id'][p]  \n",
        "      alab = apred['labels'][p] # prediction\n",
        "      apredrule = df.loc[df.id.str.contains(amid)]\n",
        "      if len(apredrule) == 0:\n",
        "        print(amid, ' not found ')\n",
        "        continue\n",
        "      for i in apredrule.index:    \n",
        "        astart = apredrule['start'][i]\n",
        "        aend = apredrule['end'][i]\n",
        "        atext = apredrule['text'][i]\n",
        "        text = atext\n",
        "        #print(a,amid,alab,atext)\n",
        "\n",
        "        print('|', atext) \n",
        "        if alab == 1: # positive prediction (what if there are multiple?) \n",
        "          print('v')\n",
        "          return amid, alab, atext, astart, aend, 75 # certain but not 100 \n",
        "        else:\n",
        "          if len(ctext) > 0:\n",
        "            if atext == ctext or ctext in atext or atext in ctext:\n",
        "              if len(arule.index) > count:\n",
        "                print('x',count)\n",
        "                continue  \n",
        "              atext, index = separate_from(atext, ctext)# restore\n",
        "              print('$',atext)\n",
        "              return amid, alab, atext, astart, aend, 0 # 0=Error\n",
        "\n",
        "            adeps,cdeps,aloops,cloops = track(verbs, atext, ctext, sentence)\n",
        "            print(adeps,cdeps,aloops,cloops)\n",
        "\n",
        "            if len(adeps)==0 and len(cdeps)==0 and len(aloops)==0 and len(cloops)==0:\n",
        "              if first and len(arule.index) > count:\n",
        "                print('x',count)\n",
        "                continue \n",
        "              return amid, alab, atext, astart, aend, '-25' # very unlikely\n",
        "\n",
        "            if len(adeps)>0 and len(cdeps)>0 and len(aloops)>0 and len(cloops)>0:\n",
        "              if len(arule.index) > count:\n",
        "                print('x',count)\n",
        "                continue    \n",
        "              return amid, alab, atext, astart, aend, '-75' # should be impossible\n",
        "\n",
        "            if len(adeps) > 0 and len(cdeps) > 0: # relaxed for correction\n",
        "              if first and len(arule.index) > count:\n",
        "                print('x',count)\n",
        "                continue\n",
        "            if len(aloops)>0 or len(cloops) >0:\n",
        "              if len(aloops)>0:\n",
        "                atext = atext + ' ' + ctext\n",
        "              else:\n",
        "                atext = ctext + ' ' + atext\n",
        "              aend = aend + 1 + len(ctext) # plus 1 space \n",
        "              print('+' , atext)   \n",
        "              return amid, alab, atext, astart, aend,'-50' # certainly-not\n",
        "            print('v')              \n",
        "            return amid, alab, atext, astart, aend, 50 # uncertain     \n",
        "  print('v')\n",
        "  return amid, alab, atext, astart, aend, 25 # unpredicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCRAUxWcq7Gp",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "original = \"If that was my daughter, I would have asked If I did something wrong.\"    \n",
        "\n",
        "prediction = predictor.predict(sentence = original)\n",
        "sentence, spans, deps, verbs = extract_dependents(prediction)\n",
        "\n",
        "verbs = follow_children(verbs) # flatten the tree\n",
        "antecedent = \"If that was my daughter\"\n",
        "consequent = \"would have asked If I did something wrong\"\n",
        "\n",
        "sentence = normalize(sentence)\n",
        "adeps, cdeps, aloops, cloops = track(verbs, antecedent, consequent, sentence)\n",
        "print(adeps,cdeps)\n",
        "print(aloops,cloops)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QUPpOr6t6udV",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "prefix = '/content/'\n",
        "\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "submit_df = pd.DataFrame(columns=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid'])\n",
        "report_df = pd.DataFrame(columns=['sentenceID','clabel','cprob','cdep','consequent','cstart','cend','gold_consequent','gold_antecedent','antecedent', 'alabel','aprob','astart','aend'])\n",
        "\n",
        "count = 0\n",
        "for ind in tqdm(test_df.index): \n",
        "  original = test_df['text'][ind]\n",
        "  id = test_df['id'][ind]\n",
        "  print(id)\n",
        "\n",
        "  sentence = original.replace('\\\"','')\n",
        "  prediction = predictor.predict(sentence)\n",
        "  rebuilt, spans, deps, verbs = extract_dependents(prediction)\n",
        "  verbs = follow_children(verbs) # flatten the   \n",
        "  sentence = normalize(rebuilt)\n",
        "\n",
        "  astart=-1\n",
        "  aend = -1\n",
        "  cstart=-1\n",
        "  cend = -1\n",
        "  text =str()\n",
        "  atext=str()  \n",
        "  ctext=str()\n",
        "\n",
        "  cid, clab, ctext, cstart, cend, cprob = analyze(id, c_df, rc_df, sentence, verbs, atext)\n",
        "  aid, alab, atext, astart, aend, aprob = analyze(id, a_df, ra_df, sentence, verbs, ctext)\n",
        "  if aprob == '-50':\n",
        "    ctext = atext\n",
        "    aid, alab, atext, astart, aend, aprob = analyze(id, a_df, ra_df, sentence, verbs, ctext, False)\n",
        "    if aprob == 0:\n",
        "      cid,clab,ctext, cstart, cend, cprob = analyze(id, c_df, rc_df, sentence, verbs, atext, False)  \n",
        "  else:  \n",
        "    cid, clab, ctext, cstart, cend, cprob = analyze(id, c_df, rc_df, sentence, verbs, atext, False)\n",
        "    if cprob == '-50':\n",
        "      atext = ctext\n",
        "      cid, clab, ctext, cstart, cend, cprob = analyze(id, c_df, rc_df, sentence, verbs, atext, False)\n",
        "\n",
        "  consequent = ctext\n",
        "  antecedent = atext\n",
        "  print(antecedent)\n",
        "  print(consequent)\n",
        "\n",
        "  cdep = '' # Pass\n",
        "  if consequent == antecedent:\n",
        "    consequent = ''\n",
        "    cstart=-1\n",
        "    cend = -1\n",
        "    cdep = '='\n",
        "  if len(verbs) > 0 and len(consequent) > 0 and not consequent in antecedent:\n",
        "    adeps,cdeps,aloops,cloops = track(verbs, antecedent, consequent, sentence)\n",
        "\n",
        "    if len(adeps) > 0 and len(cdeps) > 0 and len(aloops) > 0 and len(cloops)>0:\n",
        "      antecedent = consequent\n",
        "      astart=cstart\n",
        "      aend = cend\n",
        "      aprob= cprob\n",
        "      consequent = ''\n",
        "      cstart=-1\n",
        "      cend = -1\n",
        "      cdep = '>'\n",
        "    elif len(adeps)>0 and len(cdeps)>0:\n",
        "      cdep = '?'  \n",
        "\n",
        "  if len(antecedent) > 0:       \n",
        "    if len(consequent) > 0:\n",
        "      text = antecedent + ' | ' + consequent\n",
        "    else:\n",
        "      text = antecedent\n",
        "  else:\n",
        "    cdep = '!'      \n",
        "\n",
        "  print(cdep) # post-correction\n",
        "  if len(cdep) > 0:\n",
        "    count=count+1\n",
        "\n",
        "  report_row = pd.Series( data={\n",
        "    'sentenceID': id,\n",
        "    'clabel': clab,\n",
        "    'cprob': cprob,\n",
        "    'cdep' : cdep,\n",
        "    'consequent': consequent, # comment out gold_,\n",
        "    'cstart': cstart,\n",
        "    'cend': cend,\n",
        "    'gold_consequent': test_df['consequent'][ind],\n",
        "    'gold_antecedent': test_df['antecedent'][ind],\n",
        "    'antecedent': antecedent, \n",
        "    'alabel': alab,\n",
        "    'aprob': aprob,\n",
        "    'astart': astart,\n",
        "    'aend': aend\n",
        "  }, name = str(id) )\n",
        "\n",
        "  result_row = pd.Series( data={\n",
        "    'sentenceID': id,\n",
        "    'antecedent_startid':astart,\n",
        "    'antecedent_endid': aend,\n",
        "    'consequent_startid': cstart,\n",
        "    'consequent_endid': cend\n",
        "  }, name = str(id) )\n",
        "\n",
        "  submit_df = submit_df.append(result_row, ignore_index=True)\n",
        "  report_df = report_df.append(report_row, ignore_index=True)\n",
        "\n",
        "  print(id, text, astart, aend, cstart, cend)\n",
        "  sleep(1)\n",
        "\n",
        "submit_df.to_csv(prefix+'subtask2.csv',index=False, header=['sentenceID','antecedent_startid','antecedent_endid','consequent_startid','consequent_endid']) \n",
        "report_df.to_csv(prefix+'report.csv',index=False, header=['sentenceID','clabel','cprob','cdep','consequent','cstart','cend','gold_consequent','gold_antecedent','antecedent','alabel','aprob','astart','aend'])\n",
        "print('Falied =',count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib77s9dReMcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip submission_task2.zip subtask2.csv\n",
        "!mv /content/submission_task2.zip /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/\n",
        "!mv /content/report.csv /content/gdrive/My\\ Drive/Colab\\ Notebooks/Subtask-2/"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}